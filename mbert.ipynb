{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tariquzzaman-faisal/VITD/blob/main/mbert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting"
      ],
      "metadata": {
        "id": "rDsqhNAuDWRM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx6G9QHsDG5N",
        "outputId": "fae4210f-47a5-4de1-b8c1-4761cc303310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYWbAa4AJtP0",
        "outputId": "fb29a87f-33ff-4806-926b-3bdbbbce93dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Aug 16 18:44:16 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P0    32W /  70W |   7883MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Setup"
      ],
      "metadata": {
        "id": "pIL4P3KiDcZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiNuZb0KDndE",
        "outputId": "5a0593af-b932-49b2-fbc8-45ea59eef733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "YC1mqpRRDbLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "d_g0S_p1Jw9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load pre-trained mBERT model and tokenizer"
      ],
      "metadata": {
        "id": "ma-xOJZmDiAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'bert-base-multilingual-cased'\n",
        "num_classes = 3  # Update with the number of classes in your task\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_classes)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikMHA79ADkvZ",
        "outputId": "b4c57251-572f-497b-a2ac-8a61ccd1fb72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading dataset"
      ],
      "metadata": {
        "id": "VhPclq4xGbLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV data\n",
        "dir = '/content/drive/MyDrive/Research/Shared Task/Violence Inciting Text Detection (VITD) Bangla/dataset/Tariq/split/'\n",
        "train_data = pd.read_csv(f'{dir}train.csv')\n",
        "test_data = pd.read_csv(f'{dir}test.csv')\n",
        "val_data = pd.read_csv(f'{dir}validation.csv')"
      ],
      "metadata": {
        "id": "cQ4h__AvGcSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model setup"
      ],
      "metadata": {
        "id": "AP5FmYraIGnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(data, max_length):\n",
        "    encodings = tokenizer(data['sentence1'].tolist(), truncation=True, padding='max_length', max_length=max_length, return_tensors='pt')\n",
        "    labels = torch.tensor(data['label'].tolist()).to(device)\n",
        "    dataset = TensorDataset(encodings.input_ids.to(device), encodings.attention_mask.to(device), labels)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "b3lIwcfjHHRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 256  # Set your desired max sequence length\n",
        "train_dataset = preprocess_data(train_data, max_length)\n",
        "val_dataset = preprocess_data(val_data, max_length)\n",
        "test_dataset = preprocess_data(test_data, max_length)"
      ],
      "metadata": {
        "id": "H_hHeEt_HVV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "nKPsgeeEHbNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer and loss function\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "fWj27s7NIJRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "mSD_ZU-WIO8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the model to the same device as device\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "EGr8Fw6mK16N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define early stopping parameters\n",
        "early_stopping_patience = 3\n",
        "best_val_loss = float('inf')\n",
        "epochs_since_last_improvement = 0\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20  # Increased the number of epochs\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids, attention_mask, labels = batch\n",
        "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            val_loss += loss.item()\n",
        "            predicted_labels = torch.argmax(outputs.logits, dim=1)\n",
        "            correct += (predicted_labels == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    val_accuracy = correct / total\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "    print(f\"Avg. Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # Early stopping check\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        epochs_since_last_improvement = 0\n",
        "    else:\n",
        "        epochs_since_last_improvement += 1\n",
        "        if epochs_since_last_improvement >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered. Stopping training.\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcRVuCHJINnq",
        "outputId": "66e51af8-9482-42eb-cf68-5e52a0c080e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20]\n",
            "Validation Accuracy: 0.7128\n",
            "Avg. Validation Loss: 0.7064\n",
            "Epoch [2/20]\n",
            "Validation Accuracy: 0.7353\n",
            "Avg. Validation Loss: 0.6349\n",
            "Epoch [3/20]\n",
            "Validation Accuracy: 0.7090\n",
            "Avg. Validation Loss: 0.7366\n",
            "Epoch [4/20]\n",
            "Validation Accuracy: 0.7301\n",
            "Avg. Validation Loss: 0.8490\n",
            "Epoch [5/20]\n",
            "Validation Accuracy: 0.7444\n",
            "Avg. Validation Loss: 0.7907\n",
            "Early stopping triggered. Stopping training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving tuned model"
      ],
      "metadata": {
        "id": "4MLigAqq2RXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoConfig\n",
        "\n",
        "# Define the path to the saved model\n",
        "model_path = \"/content/drive/MyDrive/Research/Shared Task/Violence Inciting Text Detection (VITD) Bangla/models/mbert/mbert_trained_model.pth\"\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), model_path)"
      ],
      "metadata": {
        "id": "p60csnf2hYa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the model\n",
        "model2 = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_classes)\n",
        "\n",
        "# Load the saved parameters into the model\n",
        "model2.load_state_dict(torch.load(model_path))"
      ],
      "metadata": {
        "id": "KtF-jL1thgEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64a025b1-5a25-4323-dcf0-3844295ddd44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Report on test set"
      ],
      "metadata": {
        "id": "vCJResrgJUhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "6oNyHjWfJQtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test set\n",
        "model2.to(device)  # Move the model to the same device as tensors\n",
        "model2.eval()\n",
        "test_labels_list = []\n",
        "predicted_labels_list = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
        "        outputs = model2(input_ids, attention_mask=attention_mask)\n",
        "        predicted_labels = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "        test_labels_list.extend(labels.cpu().numpy())\n",
        "        predicted_labels_list.extend(predicted_labels.cpu().numpy())\n",
        "\n",
        "test_labels_np = np.array(test_labels_list)\n",
        "predicted_labels_np = np.array(predicted_labels_list)"
      ],
      "metadata": {
        "id": "_gFhVgsoJTzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate classification report\n",
        "from sklearn.metrics import classification_report\n",
        "target_names = [\"0\", \"1\", \"2\"]  # Replace with your class names\n",
        "report = classification_report(test_labels_np, predicted_labels_np, target_names=target_names)\n",
        "\n",
        "# Print the classification report\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2npgYY6gKFlT",
        "outputId": "c1c8e6fa-f2ea-4575-a861-8d538b1ca31c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.64      0.78      2016\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.64      2016\n",
            "   macro avg       0.33      0.21      0.26      2016\n",
            "weighted avg       1.00      0.64      0.78      2016\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with index and prediction columns\n",
        "result_df = pd.DataFrame({\n",
        "    'index': range(len(test_labels_np)),\n",
        "    'prediction': predicted_labels_np\n",
        "})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "result_df.to_csv('/content/drive/MyDrive/Research/Shared Task/Violence Inciting Text Detection (VITD) Bangla/models/mbert/predictions.csv', index=False)\n",
        "print(\"Predictions saved to 'predictions.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAKKOi_OZVWD",
        "outputId": "052a1496-a47a-4d13-a5ce-385a93689171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to 'predictions.csv'\n"
          ]
        }
      ]
    }
  ]
}